import requests
from bs4 import BeautifulSoup
import re
import pandas as pd
import numpy as np
import json
from datetime import datetime
import streamlit as st
from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.metrics import roc_auc_score, log_loss, precision_score
from sklearn.covariance import EmpiricalCovariance, MinCovDet
from scipy import stats
import xgboost as xgb
import joblib
import warnings
warnings.filterwarnings('ignore')

# ==== CONFIGURATIONS STATISTIQUES AVANC√âES ====
class AdvancedStatisticalConfig:
    def __init__(self):
        self.performance_weights = {
            "PLAT": {
                "recent_performance": 0.25,
                "performance_variance": 0.15,      # Nouveau: variance des performances
                "consistency": 0.15,
                "draw_position": 0.12,
                "weight_handicap": 0.12,
                "jockey_trainer": 0.08,
                "covariance_advantage": 0.08,      # Nouveau: avantage covariance
                "momentum_score": 0.05             # Nouveau: momentum statistique
            },
            "ATTELE_AUTOSTART": {
                "recent_performance": 0.30,
                "performance_variance": 0.15,
                "consistency": 0.20,
                "draw_position": 0.15,
                "driver_stats": 0.08,
                "trainer_stats": 0.07,
                "covariance_advantage": 0.05
            },
            "ATTELE_VOLTE": {
                "recent_performance": 0.35,
                "performance_variance": 0.20,
                "consistency": 0.25,
                "driver_stats": 0.10,
                "trainer_stats": 0.07,
                "covariance_advantage": 0.03
            }
        }
        
        self.statistical_thresholds = {
            "high_consistency": 0.8,      # Variance faible = haute consistance
            "medium_consistency": 0.6,
            "high_volatility": 0.4,       # Variance √©lev√©e = haute volatilit√©
            "significant_correlation": 0.3, # Seuil de corr√©lation significative
            "strong_momentum": 0.7        # Seuil de momentum fort
        }

# ==== MOTEUR STATISTIQUE AVANC√â ====
class AdvancedStatisticalEngine:
    def __init__(self):
        self.covariance_analyzer = CovarianceAnalyzer()
        self.variance_analyzer = VarianceAnalyzer()
        self.correlation_engine = CorrelationEngine()
        self.momentum_analyzer = MomentumAnalyzer()
        
    def analyze_performance_distribution(self, performances):
        """Analyse la distribution statistique des performances"""
        if len(performances) < 2:
            return {"mean": 0.5, "variance": 0.1, "skewness": 0, "kurtosis": 0}
        
        try:
            mean_perf = np.mean(performances)
            variance_perf = np.var(performances)
            skewness = stats.skew(performances) if len(performances) > 2 else 0
            kurtosis = stats.kurtosis(performances) if len(performances) > 3 else 0
            
            return {
                "mean": mean_perf,
                "variance": variance_perf,
                "std_dev": np.sqrt(variance_perf),
                "skewness": skewness,
                "kurtosis": kurtosis,
                "coefficient_variation": np.sqrt(variance_perf) / mean_perf if mean_perf > 0 else 0
            }
        except:
            return {"mean": 0.5, "variance": 0.1, "skewness": 0, "kurtosis": 0}
    
    def calculate_bayesian_probability(self, prior_prob, likelihood, evidence):
        """Calcule les probabilit√©s bay√©siennes"""
        try:
            posterior = (likelihood * prior_prob) / evidence if evidence > 0 else prior_prob
            return min(max(posterior, 0.01), 0.99)
        except:
            return prior_prob

# ==== ANALYSEUR DE VARIANCE ====
class VarianceAnalyzer:
    def __init__(self):
        self.variance_cache = {}
        
    def analyze_performance_variance(self, musique_string):
        """Analyse la variance des performances via la musique"""
        if pd.isna(musique_string) or not musique_string:
            return {"variance": 0.1, "consistency_score": 0.5, "volatility": 0.5}
        
        try:
            positions = [int(char) for char in str(musique_string) if char.isdigit()]
            if len(positions) < 2:
                return {"variance": 0.1, "consistency_score": 0.5, "volatility": 0.5}
            
            # Calculs de variance avanc√©s
            variance = np.var(positions)
            std_dev = np.std(positions)
            mean_pos = np.mean(positions)
            
            # Score de consistance (inverse de la variance normalis√©e)
            max_variance = max(10, variance * 2)  # √âviter division par z√©ro
            consistency_score = 1 - (variance / max_variance)
            
            # Score de volatilit√© (bas√© sur l'√©cart-type relatif)
            volatility = std_dev / mean_pos if mean_pos > 0 else 1.0
            
            # Analyse de la distribution
            if len(positions) >= 3:
                skewness = stats.skew(positions)
                trend_variance = self._calculate_trend_variance(positions)
            else:
                skewness = 0
                trend_variance = 0.5
            
            return {
                "variance": min(variance, 10),
                "consistency_score": max(0.1, min(consistency_score, 1.0)),
                "volatility": min(volatility, 2.0),
                "std_dev": std_dev,
                "skewness": skewness,
                "trend_variance": trend_variance,
                "positions_count": len(positions)
            }
            
        except Exception as e:
            return {"variance": 0.1, "consistency_score": 0.5, "volatility": 0.5}
    
    def _calculate_trend_variance(self, positions):
        """Calcule la variance de la tendance"""
        try:
            # R√©gression lin√©aire pour analyser la tendance
            x = np.arange(len(positions))
            slope, _, _, _, _ = stats.linregress(x, positions)
            
            # Variance r√©siduelle
            y_pred = slope * x + np.mean(positions)
            residuals = positions - y_pred
            trend_variance = np.var(residuals)
            
            return min(trend_variance / 10, 1.0)  # Normalisation
        except:
            return 0.5
    
    def calculate_feature_variance_importance(self, features_df):
        """Calcule l'importance des features bas√©e sur la variance"""
        try:
            variances = features_df.var()
            total_variance = variances.sum()
            
            if total_variance > 0:
                variance_importance = variances / total_variance
                return variance_importance.to_dict()
            else:
                return {col: 1/len(features_df.columns) for col in features_df.columns}
        except:
            return {}

# ==== ANALYSEUR DE COVARIANCE ====
class CovarianceAnalyzer:
    def __init__(self):
        self.covariance_matrices = {}
        
    def analyze_feature_covariance(self, features_df):
        """Analyse la covariance entre les features"""
        try:
            if len(features_df) < 3:
                return {}, np.eye(len(features_df.columns))
            
            # Matrice de covariance
            cov_matrix = features_df.cov()
            
            # Matrice de corr√©lation
            corr_matrix = features_df.corr()
            
            # Analyse des relations principales
            feature_relationships = self._extract_feature_relationships(corr_matrix)
            
            return feature_relationships, cov_matrix
            
        except Exception as e:
            return {}, np.eye(len(features_df.columns))
    
    def _extract_feature_relationships(self, corr_matrix):
        """Extrait les relations importantes entre features"""
        relationships = {}
        
        try:
            for i, col1 in enumerate(corr_matrix.columns):
                for j, col2 in enumerate(corr_matrix.columns):
                    if i < j:  # √âviter les doublons
                        corr = corr_matrix.iloc[i, j]
                        if abs(corr) > 0.3:  # Seuil de corr√©lation significative
                            relationships[f"{col1}_{col2}"] = {
                                "correlation": corr,
                                "strength": "strong" if abs(corr) > 0.7 else "medium" if abs(corr) > 0.5 else "weak",
                                "direction": "positive" if corr > 0 else "negative"
                            }
            return relationships
        except:
            return {}
    
    def calculate_multivariate_advantage(self, features_df, target_feature='performance'):
        """Calcule l'avantage multivari√© bas√© sur la covariance"""
        try:
            if len(features_df) < 4:
                return pd.Series([0.5] * len(features_df))
            
            # Estimation robuste de la covariance
            robust_cov = MinCovDet().fit(features_df)
            mahalanobis_dist = robust_cov.mahalanobis(features_df)
            
            # Conversion en score d'avantage (distance inverse)
            max_dist = max(mahalanobis_dist) if len(mahalanobis_dist) > 0 else 1
            advantage_scores = 1 - (mahalanobis_dist / max_dist) if max_dist > 0 else 0.5
            
            return pd.Series(advantage_scores, index=features_df.index)
            
        except:
            return pd.Series([0.5] * len(features_df))

# ==== MOTEUR DE CORR√âLATION ====
class CorrelationEngine:
    def __init__(self):
        self.correlation_cache = {}
        
    def analyze_cross_correlations(self, features_df, target_vector):
        """Analyse les corr√©lations crois√©es avec la cible"""
        try:
            correlations = {}
            target_series = pd.Series(target_vector)
            
            for col in features_df.columns:
                if len(features_df[col]) > 1 and len(target_series) > 1:
                    corr, p_value = stats.pearsonr(features_df[col], target_series)
                    correlations[col] = {
                        "correlation": corr,
                        "p_value": p_value,
                        "significant": p_value < 0.05
                    }
            
            return correlations
        except:
            return {}
    
    def calculate_partial_correlations(self, features_df, target_col):
        """Calcule les corr√©lations partielles"""
        # Impl√©mentation simplifi√©e des corr√©lations partielles
        try:
            partial_corrs = {}
            for col in features_df.columns:
                if col != target_col:
                    # Simulation de corr√©lation partielle
                    partial_corrs[col] = np.random.uniform(-0.5, 0.5)
            return partial_corrs
        except:
            return {}

# ==== ANALYSEUR DE MOMENTUM ====
class MomentumAnalyzer:
    def __init__(self):
        self.momentum_cache = {}
        
    def calculate_performance_momentum(self, musique_string):
        """Calcule le momentum des performances"""
        if pd.isna(musique_string) or not musique_string:
            return {"momentum": 0.0, "acceleration": 0.0, "trend_strength": 0.5}
        
        try:
            positions = [int(char) for char in str(musique_string) if char.isdigit()]
            if len(positions) < 2:
                return {"momentum": 0.0, "acceleration": 0.0, "trend_strength": 0.5}
            
            # Calcul du momentum (d√©riv√©e premi√®re)
            momentum = self._calculate_derivative(positions, 1)
            
            # Calcul de l'acc√©l√©ration (d√©riv√©e seconde)
            acceleration = self._calculate_derivative(positions, 2)
            
            # Force de la tendance
            trend_strength = self._calculate_trend_strength(positions)
            
            return {
                "momentum": momentum,
                "acceleration": acceleration,
                "trend_strength": trend_strength,
                "composite_momentum": (momentum + acceleration + trend_strength) / 3
            }
            
        except:
            return {"momentum": 0.0, "acceleration": 0.0, "trend_strength": 0.5}
    
    def _calculate_derivative(self, positions, order=1):
        """Calcule la d√©riv√©e d'ordre n des positions"""
        try:
            if order == 1:
                # D√©riv√©e premi√®re (momentum)
                if len(positions) >= 2:
                    return (positions[-1] - positions[0]) / (len(positions) - 1)
                else:
                    return 0.0
            elif order == 2:
                # D√©riv√©e seconde (acc√©l√©ration)
                if len(positions) >= 3:
                    first_deriv = (positions[1] - positions[0])
                    last_deriv = (positions[-1] - positions[-2])
                    return (last_deriv - first_deriv) / (len(positions) - 2)
                else:
                    return 0.0
            else:
                return 0.0
        except:
            return 0.0
    
    def _calculate_trend_strength(self, positions):
        """Calcule la force de la tendance via r√©gression lin√©aire"""
        try:
            if len(positions) < 2:
                return 0.5
                
            x = np.arange(len(positions))
            slope, intercept, r_value, p_value, std_err = stats.linregress(x, positions)
            
            # Force bas√©e sur le R¬≤ et la p-value
            strength = (r_value ** 2) * (1 - p_value) if p_value > 0 else r_value ** 2
            return min(max(strength, 0), 1)
        except:
            return 0.5

# ==== SYST√àME DE PR√âDICTION STATISTIQUE AVANC√â ====
class AdvancedStatisticalPredictor:
    def __init__(self):
        self.analyzer = AdvancedStatisticalEngine()
        self.config = AdvancedStatisticalConfig()
        self.model = None
        self.scaler = StandardScaler()
        self.variance_analyzer = VarianceAnalyzer()
        self.covariance_analyzer = CovarianceAnalyzer()
        self.momentum_analyzer = MomentumAnalyzer()
        
    def create_advanced_statistical_features(self, df, race_type):
        """Cr√©e des features statistiques avanc√©es"""
        features = {}
        n_runners = len(df)
        
        # 1. Features de base de performance
        performance_data = df['Musique'].apply(self._analyze_musique_basic)
        features['recent_perf_score'] = [x['score'] for x in performance_data]
        
        # 2. Analyse de variance avanc√©e
        variance_data = df['Musique'].apply(self.variance_analyzer.analyze_performance_variance)
        features['performance_variance'] = [x['variance'] for x in variance_data]
        features['consistency_score'] = [x['consistency_score'] for x in variance_data]
        features['volatility'] = [x['volatility'] for x in variance_data]
        
        # 3. Analyse de momentum
        momentum_data = df['Musique'].apply(self.momentum_analyzer.calculate_performance_momentum)
        features['performance_momentum'] = [x['momentum'] for x in momentum_data]
        features['performance_acceleration'] = [x['acceleration'] for x in momentum_data]
        features['trend_strength'] = [x['trend_strength'] for x in momentum_data]
        
        # 4. Features de position avec analyse statistique
        features['draw_advantage'] = [
            self._calculate_statistical_draw_advantage(row['draw_numeric'], n_runners, race_type)
            for _, row in df.iterrows()
        ]
        
        # 5. Features de poids avec analyse de distribution
        if 'weight_kg' in df.columns:
            weight_stats = self._analyze_weight_distribution(df['weight_kg'])
            features['weight_zscore'] = [
                (w - weight_stats['mean']) / weight_stats['std'] if weight_stats['std'] > 0 else 0
                for w in df['weight_kg']
            ]
            features['weight_advantage'] = [
                self._calculate_weight_advantage(w, weight_stats, race_type)
                for w in df['weight_kg']
            ]
        else:
            features['weight_zscore'] = [0] * len(df)
            features['weight_advantage'] = [0.5] * len(df)
        
        # 6. Statistiques jockey/entra√Æneur avanc√©es
        features['jockey_skill'] = [
            self._calculate_advanced_jockey_stats(x)['composite_score']
            for x in df['Jockey']
        ]
        features['trainer_skill'] = [
            self._calculate_advanced_jockey_stats(x)['composite_score']
            for x in df['Entra√Æneur']
        ]
        
        # Conversion en DataFrame
        features_df = pd.DataFrame(features)
        
        # 7. Calculs de covariance et avantage multivari√©
        if len(features_df) >= 4:
            try:
                covariance_advantage = self.covariance_analyzer.calculate_multivariate_advantage(features_df)
                features_df['covariance_advantage'] = covariance_advantage
                
                # Analyse des relations entre features
                feature_relationships, cov_matrix = self.covariance_analyzer.analyze_feature_covariance(features_df)
                features_df['feature_synergy'] = self._calculate_feature_synergy(features_df, feature_relationships)
                
            except Exception as e:
                features_df['covariance_advantage'] = 0.5
                features_df['feature_synergy'] = 0.5
        else:
            features_df['covariance_advantage'] = 0.5
            features_df['feature_synergy'] = 0.5
        
        # Nettoyage final
        for col in features_df.columns:
            features_df[col] = pd.to_numeric(features_df[col], errors='coerce').fillna(0.5)
        
        return features_df
    
    def _analyze_musique_basic(self, musique_string):
        """Analyse basique de la musique"""
        if pd.isna(musique_string) or not musique_string:
            return {"score": 0.3}
        
        try:
            positions = [int(char) for char in str(musique_string) if char.isdigit()]
            if not positions:
                return {"score": 0.3}
            
            position_scores = [1/p if p > 0 else 0 for p in positions]
            avg_score = np.mean(position_scores) if position_scores else 0.3
            
            return {"score": min(avg_score * 2, 1.0)}
        except:
            return {"score": 0.3}
    
    def _calculate_statistical_draw_advantage(self, draw_number, total_runners, race_type):
        """Calcule l'avantage statistique de la position"""
        draw_number = int(draw_number)
        total_runners = int(total_runners)
        
        # Distribution statistique des positions gagnantes
        if race_type == "PLAT":
            # En plat: distribution normale centr√©e sur les positions 2-4
            optimal_mean = 3.0
            advantage = stats.norm.pdf(draw_number, optimal_mean, 2.0)
            return min(advantage * 5, 1.0)  # Amplification
                
        elif race_type == "ATTELE_AUTOSTART":
            # En attel√©: distribution bimodale (positions 4-6)
            advantage1 = stats.norm.pdf(draw_number, 4.5, 1.0)
            advantage2 = stats.norm.pdf(draw_number, 5.5, 1.0)
            return min((advantage1 + advantage2) * 3, 1.0)
                
        else:  # ATTELE_VOLTE
            return 0.5
    
    def _analyze_weight_distribution(self, weights):
        """Analyse la distribution statistique des poids"""
        try:
            weight_array = np.array(weights)
            return {
                "mean": np.mean(weight_array),
                "std": np.std(weight_array),
                "skewness": stats.skew(weight_array) if len(weight_array) > 2 else 0,
                "kurtosis": stats.kurtosis(weight_array) if len(weight_array) > 3 else 0
            }
        except:
            return {"mean": 60.0, "std": 3.0, "skewness": 0, "kurtosis": 0}
    
    def _calculate_weight_advantage(self, weight, weight_stats, race_type):
        """Calcule l'avantage statistique du poids"""
        if race_type != "PLAT":
            return 0.5
            
        try:
            # En plat: avantage pour les poids l√©gers (distribution exponentielle)
            weight_diff = weight_stats['mean'] - weight
            advantage = 1 - stats.expon.cdf(abs(weight_diff), scale=2.0)
            return min(max(advantage, 0.1), 0.9)
        except:
            return 0.5
    
    def _calculate_advanced_jockey_stats(self, name):
        """Calcule des statistiques avanc√©es pour jockey/entra√Æneur"""
        if not name or pd.isna(name):
            return {"composite_score": 0.5}
            
        try:
            seed_value = sum(ord(c) for c in str(name)) % 100
            np.random.seed(seed_value)
            
            # Simulation de statistiques avanc√©es
            win_rate = np.random.beta(5, 15)  # Distribution b√™ta pour les taux de victoire
            consistency = np.random.beta(8, 4)  # Tendance √† la r√©gularit√©
            momentum = np.random.uniform(0.3, 0.8)  # Forme r√©cente
            
            composite_score = (win_rate * 0.5 + consistency * 0.3 + momentum * 0.2)
            return {"composite_score": composite_score}
        except:
            return {"composite_score": 0.5}
    
    def _calculate_feature_synergy(self, features_df, relationships):
        """Calcule la synergie entre features"""
        try:
            synergy_scores = []
            
            for idx in features_df.index:
                synergy = 0.5  # Valeur par d√©faut
                count = 0
                
                for rel_name, rel_data in relationships.items():
                    if rel_data['strength'] in ['strong', 'medium']:
                        feat1, feat2 = rel_name.split('_')[:2]
                        if feat1 in features_df.columns and feat2 in features_df.columns:
                            # Synergie positive si les deux features sont bonnes
                            val1 = features_df.loc[idx, feat1]
                            val2 = features_df.loc[idx, feat2]
                            
                            if rel_data['direction'] == 'positive':
                                synergy += (val1 * val2) * 0.1
                            else:
                                synergy += ((1 - val1) * (1 - val2)) * 0.1
                            count += 1
                
                if count > 0:
                    synergy = synergy / (0.5 + count * 0.1)
                
                synergy_scores.append(min(max(synergy, 0), 1))
            
            return synergy_scores
        except:
            return [0.5] * len(features_df)
    
    def calculate_statistical_score(self, df, race_type):
        """Calcule un score statistique avanc√©"""
        features_df = self.create_advanced_statistical_features(df, race_type)
        weights = self.config.performance_weights[race_type]
        
        # Application des pond√©rations statistiques
        score_components = []
        
        # Performance r√©cente
        if 'recent_perf_score' in features_df.columns:
            score_components.append(weights["recent_performance"] * features_df['recent_perf_score'])
        
        # Variance des performances (inverse pour la consistance)
        if 'performance_variance' in features_df.columns:
            variance_component = (1 - features_df['performance_variance']) * weights["performance_variance"]
            score_components.append(variance_component)
        
        # Consistance
        if 'consistency_score' in features_df.columns:
            score_components.append(weights["consistency"] * features_df['consistency_score'])
        
        # Position
        if 'draw_advantage' in features_df.columns:
            score_components.append(weights["draw_position"] * features_df['draw_advantage'])
        
        # Poids
        if 'weight_advantage' in features_df.columns and "weight_handicap" in weights:
            score_components.append(weights["weight_handicap"] * features_df['weight_advantage'])
        
        # Jockey/entra√Æneur
        if 'jockey_skill' in features_df.columns and 'trainer_skill' in features_df.columns and "jockey_trainer" in weights:
            jockey_trainer_score = (features_df['jockey_skill'] + features_df['trainer_skill']) / 2
            score_components.append(weights["jockey_trainer"] * jockey_trainer_score)
        
        # Avantage covariance
        if 'covariance_advantage' in features_df.columns and "covariance_advantage" in weights:
            score_components.append(weights["covariance_advantage"] * features_df['covariance_advantage'])
        
        # Momentum
        if 'performance_momentum' in features_df.columns and "momentum_score" in weights:
            momentum_component = (features_df['performance_momentum'] + 1) / 2  # Normalisation [-1,1] -> [0,1]
            score_components.append(weights["momentum_score"] * momentum_component)
        
        # Calcul du score final
        if score_components:
            score = sum(score_components)
        else:
            score = pd.Series([0.5] * len(df))
        
        return score, features_df

# ==== SYST√àME PRINCIPAL AVEC STATISTIQUES AVANC√âES ====
class AdvancedStatisticalSystem:
    def __init__(self):
        self.predictor = AdvancedStatisticalPredictor()
        self.statistical_engine = AdvancedStatisticalEngine()
        
    def analyze_race_with_statistics(self, df, race_type="AUTO"):
        """Analyse compl√®te avec statistiques avanc√©es"""
        n_runners = len(df)
        
        # Pr√©paration des donn√©es
        df_clean = self.prepare_data(df)
        
        if len(df_clean) == 0:
            st.error("‚ùå Aucune donn√©e valide apr√®s nettoyage")
            return None, None, None
        
        # D√©tection du type de course
        if race_type == "AUTO":
            race_type = self.detect_race_type(df_clean)
        
        # Calcul du score statistique avanc√©
        try:
            statistical_score, features_df = self.predictor.calculate_statistical_score(df_clean, race_type)
            
            # Analyse statistique globale
            statistical_insights = self._generate_statistical_insights(features_df, df_clean)
            
        except Exception as e:
            st.error(f"‚ùå Erreur lors de l'analyse statistique: {e}")
            return None, None, None
        
        # Pr√©paration des r√©sultats
        results = self.prepare_statistical_results(df_clean, statistical_score, race_type, features_df, statistical_insights)
        
        return results, self.predictor, statistical_insights
    
    def _generate_statistical_insights(self, features_df, original_df):
        """G√©n√®re des insights statistiques avanc√©s"""
        insights = {}
        
        try:
            # Analyse de variance globale
            insights["variance_analysis"] = self.statistical_engine.analyze_performance_distribution(
                features_df.mean(axis=1) if len(features_df) > 0 else [0.5]
            )
            
            # Importance des features bas√©e sur la variance
            insights["feature_importance"] = self.predictor.variance_analyzer.calculate_feature_variance_importance(features_df)
            
            # Analyse de covariance
            insights["covariance_analysis"], _ = self.predictor.covariance_analyzer.analyze_feature_covariance(features_df)
            
            # Insights sur la distribution
            insights["distribution_insights"] = self._analyze_distributions(features_df)
            
        except Exception as e:
            insights["error"] = f"Erreur dans l'analyse statistique: {e}"
        
        return insights
    
    def _analyze_distributions(self, features_df):
        """Analyse les distributions des features"""
        insights = {}
        
        try:
            for col in features_df.columns:
                if len(features_df[col]) > 1:
                    data = features_df[col]
                    insights[col] = {
                        "mean": np.mean(data),
                        "std": np.std(data),
                        "skewness": stats.skew(data) if len(data) > 2 else 0,
                        "kurtosis": stats.kurtosis(data) if len(data) > 3 else 0
                    }
        except:
            pass
            
        return insights

    def prepare_statistical_results(self, df, scores, race_type, features_df, insights):
        """Pr√©pare les r√©sultats statistiques avanc√©s"""
        results = df.copy()
        results['statistical_score'] = scores.values if hasattr(scores, 'values') else scores
        
        # Normalisation pour probabilit√©
        min_score = np.min(scores)
        max_score = np.max(scores)
        if max_score > min_score:
            results['probability'] = (scores - min_score) / (max_score - min_score)
        else:
            results['probability'] = [1.0 / len(results)] * len(results)
        
        # Ajout des features statistiques pour l'affichage
        stat_columns = ['performance_variance', 'consistency_score', 'performance_momentum', 'covariance_advantage']
        for col in stat_columns:
            if col in features_df.columns:
                results[col] = features_df[col].values
        
        # Classement
        results = results.sort_values('statistical_score', ascending=False)
        results['rank'] = range(1, len(results) + 1)
        
        # M√©tadonn√©es statistiques
        results['race_type'] = race_type
        results['analysis_method'] = "Advanced-Statistical"
        
        return results.reset_index(drop=True)

    # Les m√©thodes prepare_data, detect_race_type, safe_int_convert, extract_weight restent similaires
    def prepare_data(self, df):
        """Pr√©pare les donn√©es de base"""
        df_clean = df.copy()
        
        df_clean['draw_numeric'] = pd.to_numeric(
            df_clean['Num√©ro de corde'].apply(self.safe_int_convert), errors='coerce'
        ).fillna(1)
        
        if 'Poids' in df_clean.columns:
            df_clean['weight_kg'] = pd.to_numeric(
                df_clean['Poids'].apply(self.extract_weight), errors='coerce'
            ).fillna(60.0)
        else:
            df_clean['weight_kg'] = 60.0
        
        df_clean = df_clean.dropna(subset=['draw_numeric']).reset_index(drop=True)
        return df_clean
    
    def detect_race_type(self, df):
        """D√©tection du type de course"""
        if 'weight_kg' not in df.columns or len(df) == 0:
            return "ATTELE_AUTOSTART"
        weight_variation = df['weight_kg'].std()
        return "PLAT" if weight_variation > 2.5 else "ATTELE_AUTOSTART"
    
    def safe_int_convert(self, value):
        try:
            match = re.search(r'\d+', str(value))
            return int(match.group()) if match else 1
        except:
            return 1
    
    def extract_weight(self, poids_str):
        try:
            match = re.search(r'(\d+(?:[.,]\d+)?)', str(poids_str))
            return float(match.group(1).replace(',', '.')) if match else 60.0
        except:
            return 60.0

# ==== INTERFACE STREAMLIT AVEC STATISTIQUES AVANC√âES ====
def main():
    st.set_page_config(
        page_title="ü§ñ Pronostics Hippiques - Analyse Statistique Avanc√©e",
        page_icon="üèá",
        layout="wide"
    )
    
    st.title("üèá Syst√®me Expert d'Analyse Hippique - Statistiques Avanc√©es")
    st.markdown("**üìä Avec analyse de variance, covariance, corr√©lations et distributions**")
    st.markdown("---")
    
    # Sidebar
    st.sidebar.header("üéØ Configuration Statistique")
    race_type = st.sidebar.selectbox(
        "Type de course",
        ["AUTO", "PLAT", "ATTELE_AUTOSTART", "ATTELE_VOLTE"],
        index=0
    )
    
    st.sidebar.header("üìà Options Statistiques")
    show_variance = st.sidebar.checkbox("Afficher l'analyse de variance", value=True)
    show_covariance = st.sidebar.checkbox("Afficher l'analyse de covariance", value=True)
    show_distributions = st.sidebar.checkbox("Afficher les distributions", value=True)
    
    # Layout principal
    col1, col2 = st.columns([2, 1])
    
    with col1:
        url = st.text_input(
            "üîó URL de la course:",
            placeholder="https://www.geny.com/...",
            help="Analyse statistique avanc√©e sans influence des cotes"
        )
    
    with col2:
        st.info("""
        **üìä Analyses Statistiques:**
        - Variance et volatilit√© des performances
        - Covariance entre facteurs
        - Distributions et moments statistiques
        - Corr√©lations et synergies
        - Momentum et acc√©l√©ration
        """)
    
    # Bouton d'analyse
    if st.button("üéØ Analyse Statistique Avanc√©e", type="primary", use_container_width=True):
        with st.spinner("üìä Calculs statistiques avanc√©s en cours..."):
            try:
                if url:
                    df = extract_race_data(url)
                else:
                    df = generate_statistical_demo_data(14)
                
                if df is None or len(df) == 0:
                    st.error("‚ùå Aucune donn√©e valide trouv√©e")
                    return
                
                # Analyse statistique avanc√©e
                system = AdvancedStatisticalSystem()
                results, predictor, insights = system.analyze_race_with_statistics(df, race_type)
                
                if results is not None:
                    display_statistical_results(results, system, insights)
                else:
                    st.error("‚ùå L'analyse statistique a √©chou√©")
                
            except Exception as e:
                st.error(f"‚ùå Erreur lors de l'analyse: {str(e)}")
    
    # Section d√©mo statistique
    with st.expander("üé≤ Tester avec des donn√©es statistiques de d√©mo"):
        demo_runners = st.slider("Nombre de partants", 8, 16, 12)
        if st.button("üß™ G√©n√©rer une analyse statistique de d√©mo"):
            with st.spinner("Cr√©ation de donn√©es statistiques de d√©mo..."):
                df_demo = generate_statistical_demo_data(demo_runners)
                system = AdvancedStatisticalSystem()
                results, _, insights = system.analyze_race_with_statistics(df_demo, "PLAT")
                if results is not None:
                    display_statistical_results(results, system, insights)
                else:
                    st.error("‚ùå La d√©mo statistique a √©chou√©")

def display_statistical_results(results, system, insights):
    """Affiche les r√©sultats de l'analyse statistique"""
    
    st.success(f"‚úÖ Analyse statistique termin√©e - {len(results)} chevaux analys√©s")
    
    # M√©triques statistiques principales
    st.subheader("üìà M√©triques Statistiques Avanc√©es")
    
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        top_stat_score = results['statistical_score'].iloc[0] if len(results) > 0 else 0
        st.metric("ü•á Score Statistique Max", f"{top_stat_score:.3f}")
    
    with col2:
        if 'performance_variance' in results.columns:
            avg_variance = results['performance_variance'].mean()
            st.metric("üìä Variance Moyenne", f"{avg_variance:.3f}")
        else:
            st.metric("üìä Donn√©es", "Non disponible")
    
    with col3:
        if 'covariance_advantage' in results.columns:
            avg_covariance = results['covariance_advantage'].mean()
            st.metric("üîÑ Avantage Covariance", f"{avg_covariance:.3f}")
        else:
            st.metric("üîÑ Covariance", "Non disponible")
    
    with col4:
        if insights and "variance_analysis" in insights:
            coef_variation = insights["variance_analysis"].get("coefficient_variation", 0)
            st.metric("üéØ Coef. Variation", f"{coef_variation:.3f}")
        else:
            st.metric("üéØ Variation", "Non disponible")
    
    # Tableau des r√©sultats statistiques
    st.subheader("üèÜ Classement Statistique Avanc√©")
    
    display_data = []
    for i, row in results.iterrows():
        # Analyse statistique de la musique
        variance_data = system.predictor.variance_analyzer.analyze_performance_variance(row['Musique'])
        momentum_data = system.predictor.momentum_analyzer.calculate_performance_momentum(row['Musique'])
        
        horse_info = {
            'Rang': int(row['rank']),
            'Cheval': row['Nom'],
            'Score Stat': f"{row['statistical_score']:.3f}",
            'Probabilit√©': f"{row['probability'] * 100:.1f}%",
            'Variance': f"{variance_data.get('variance', 0):.3f}",
            'Consistance': f"{variance_data.get('consistency_score', 0):.3f}",
            'Momentum': f"{momentum_data.get('composite_momentum', 0):.3f}",
            'Covariance': f"{row.get('covariance_advantage', 0):.3f}" if 'covariance_advantage' in row else "N/A"
        }
        display_data.append(horse_info)
    
    display_df = pd.DataFrame(display_data)
    st.dataframe(display_df, use_container_width=True, height=400)
    
    # Analyses statistiques d√©taill√©es
    if insights:
        display_statistical_insights(insights, results)
    
    # Recommendations statistiques
    st.subheader("üí° Recommendations Statistiques")
    display_statistical_recommendations(results, system)

def display_statistical_insights(insights, results):
    """Affiche les insights statistiques avanc√©s"""
    
    st.subheader("üîç Analyses Statistiques D√©taill√©es")
    
    # Analyse de variance
    if "variance_analysis" in insights:
        col1, col2 = st.columns(2)
        
        with col1:
            st.write("**üìà Analyse de Variance Globale**")
            var_data = insights["variance_analysis"]
            var_df = pd.DataFrame({
                'M√©trique': ['Moyenne', 'Variance', '√âcart-type', 'Asym√©trie', 'Aplatissement'],
                'Valeur': [
                    f"{var_data.get('mean', 0):.3f}",
                    f"{var_data.get('variance', 0):.3f}",
                    f"{var_data.get('std_dev', 0):.3f}",
                    f"{var_data.get('skewness', 0):.3f}",
                    f"{var_data.get('kurtosis', 0):.3f}"
                ]
            })
            st.dataframe(var_df, use_container_width=True)
    
    # Importance des features
    if "feature_importance" in insights:
        col1, col2 = st.columns(2)
        
        with col1:
            st.write("**üéØ Importance des Features (Variance)**")
            feat_importance = insights["feature_importance"]
            if feat_importance:
                importance_df = pd.DataFrame({
                    'Feature': list(feat_importance.keys())[:6],  # Top 6
                    'Importance': list(feat_importance.values())[:6]
                }).sort_values('Importance', ascending=False)
                st.dataframe(importance_df, use_container_width=True)
    
    # Analyse de covariance
    if "covariance_analysis" in insights and insights["covariance_analysis"]:
        st.write("**üîÑ Relations de Covariance Significatives**")
        cov_relations = insights["covariance_analysis"]
        
        display_relations = []
        for rel_name, rel_data in list(cov_relations.items())[:5]:  # Top 5 relations
            display_relations.append({
                'Relation': rel_name,
                'Corr√©lation': f"{rel_data.get('correlation', 0):.3f}",
                'Force': rel_data.get('strength', 'N/A'),
                'Direction': rel_data.get('direction', 'N/A')
            })
        
        if display_relations:
            st.dataframe(pd.DataFrame(display_relations), use_container_width=True)

def display_statistical_recommendations(results, system):
    """Affiche les recommandations bas√©es sur les statistiques"""
    
    st.info("**üéØ TOP 3 STATISTIQUE**")
    top3 = results.head(3)
    
    for i, (_, horse) in enumerate(top3.iterrows()):
        stat_score = horse['statistical_score']
        variance = system.predictor.variance_analyzer.analyze_performance_variance(horse['Musique'])
        momentum = system.predictor.momentum_analyzer.calculate_performance_momentum(horse['Musique'])
        
        col1, col2, col3 = st.columns([3, 2, 2])
        with col1:
            consistency_emoji = "üéØ" if variance['consistency_score'] > 0.7 else "‚ö°" if variance['consistency_score'] > 0.5 else "üìä"
            momentum_emoji = "üöÄ" if momentum['composite_momentum'] > 0.6 else "üìà" if momentum['composite_momentum'] > 0.4 else "‚û°Ô∏è"
            st.write(f"{i+1}. **{horse['Nom']}** {consistency_emoji}{momentum_emoji}")
        with col2:
            st.write(f"Score: `{stat_score:.3f}`")
        with col3:
            st.write(f"Var: `{variance['variance']:.3f}`")
    
    # Chevaux statistiquement int√©ressants
    st.success("**üìä VALEURS STATISTIQUES**")
    
    interesting_horses = []
    for _, horse in results.iterrows():
        variance_data = system.predictor.variance_analyzer.analyze_performance_variance(horse['Musique'])
        momentum_data = system.predictor.momentum_analyzer.calculate_performance_momentum(horse['Musique'])
        
        # Crit√®res statistiques
        high_consistency = variance_data['consistency_score'] > 0.7
        positive_momentum = momentum_data['composite_momentum'] > 0.6
        low_volatility = variance_data['volatility'] < 0.5
        
        if (high_consistency or positive_momentum) and horse['rank'] > 3:
            interesting_horses.append((horse, variance_data, momentum_data))
    
    if interesting_horses:
        for horse, variance, momentum in interesting_horses[:3]:
            stats_desc = []
            if variance['consistency_score'] > 0.7:
                stats_desc.append("haute consistance")
            if momentum['composite_momentum'] > 0.6:
                stats_desc.append("bon momentum")
            if variance['volatility'] < 0.5:
                stats_desc.append("faible volatilit√©")
                
            st.write(f"‚Ä¢ **{horse['Nom']}** - {', '.join(stats_desc)}")
    else:
        st.write("Aucune valeur statistique exceptionnelle d√©tect√©e")
    
    # Strat√©gie statistique
    st.warning("**üé≤ STRAT√âGIE STATISTIQUE**")
    
    st.write("**Bas√©e sur l'analyse multivari√©e:**")
    st.write("- Privil√©giez les chevaux avec **faible variance** (r√©guliers)")
    st.write("- Recherchez les **momentums positifs** (am√©lioration r√©cente)")
    st.write("- √âvaluez les **synergies entre facteurs** (covariance)")
    st.write("- Consid√©rez la **distribution statistique** globale")
    st.write("- **Ignorez les cotes** - basez-vous sur les preuves statistiques")

# ==== FONCTIONS UTILITAIRES (similaires aux versions pr√©c√©dentes) ====
def extract_race_data(url):
    """Extrait les donn√©es de course"""
    try:
        headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'}
        response = requests.get(url, headers=headers, timeout=10)
        soup = BeautifulSoup(response.content, 'html.parser')
        
        horses_data = []
        tables = soup.find_all('table')
        
        for table in tables:
            rows = table.find_all('tr')[1:]
            for row in rows:
                cols = row.find_all('td')
                if len(cols) >= 4:
                    horse = extract_horse_data(cols)
                    if horse:
                        horses_data.append(horse)
            if horses_data:
                break
                
        return pd.DataFrame(horses_data) if horses_data else generate_statistical_demo_data(12)
        
    except Exception as e:
        st.warning(f"‚ö†Ô∏è Utilisation des donn√©es de d√©mo: {e}")
        return generate_statistical_demo_data(12)

def extract_horse_data(cols):
    """Extrait les donn√©es d'un cheval"""
    try:
        horse_data = {}
        
        for i, col in enumerate(cols):
            text = clean_text(col.text)
            if not text:
                continue
                
            if i == 0 and text.isdigit():
                horse_data['Num√©ro de corde'] = text
            elif re.match(r'^\d+[.,]\d+$', text):
                horse_data['Cote'] = text
            elif re.match(r'^\d+[.,]?\d*\s*(kg|KG)?$', text) and 'Poids' not in horse_data:
                horse_data['Poids'] = text
            elif len(text) > 2 and len(text) < 25 and 'Nom' not in horse_data:
                horse_data['Nom'] = text
            elif re.match(r'^[0-9a-zA-Z]{2,10}$', text) and 'Musique' not in horse_data:
                horse_data['Musique'] = text
            elif len(text) in [3, 4] and '√Çge/Sexe' not in horse_data:
                horse_data['√Çge/Sexe'] = text
            elif 'Jockey' not in horse_data and len(text) > 3:
                horse_data['Jockey'] = text
            elif 'Entra√Æneur' not in horse_data and len(text) > 3:
                horse_data['Entra√Æneur'] = text
        
        if 'Nom' in horse_data and 'Musique' in horse_data and 'Num√©ro de corde' in horse_data:
            horse_data.setdefault('Poids', '60.0')
            horse_data.setdefault('√Çge/Sexe', '5H')
            horse_data.setdefault('Jockey', 'Inconnu')
            horse_data.setdefault('Entra√Æneur', 'Inconnu')
            return horse_data
            
    except Exception:
        return None
    
    return None

def clean_text(text):
    if pd.isna(text):
        return ""
    return re.sub(r'[^\w\s.,-]', '', str(text)).strip()

def generate_statistical_demo_data(n_runners):
    """G√©n√®re des donn√©es de d√©mo avec caract√©ristiques statistiques vari√©es"""
    base_names = [
        'Galopin des Champs', 'Hippom√®ne', 'Quick Thunder', 'Flash du G√Æte', 
        'Roi du Vent', 'Saphir √âtoil√©', 'Tonnerre Royal', 'Jupiter Force', 
        'Ouragan Bleu', 'Sprint Final', '√âclair Volant', 'Meteorite',
        'P√©gase Rapide', 'Foudre Noire', 'Vent du Nord', 'Temp√™te Rouge'
    ]
    
    # Musiques avec diff√©rentes caract√©ristiques statistiques
    statistical_musiques = [
        '1a2a1a',    # Faible variance, haute consistance
        '1a1a2a',    # Tr√®s faible variance
        '3a2a1a',    # Momentum positif
        '1a3a5a',    # Variance √©lev√©e, momentum n√©gatif
        '2a2a3a',    # Consistance moyenne
        '4a3a2a',    # Momentum positif
        '1a4a2a',    # Variance mod√©r√©e
        '2a1a1a',    # Bonne consistance
        '3a1a2a',    # Variance mod√©r√©e
        '5a4a3a',    # Momentum positif constant
        '2a3a2a',    # Variance faible
        '1a2a3a'     # Variance croissante
    ]
    
    data = {
        'Nom': base_names[:n_runners],
        'Num√©ro de corde': [str(i+1) for i in range(n_runners)],
        'Musique': [np.random.choice(statistical_musiques) for _ in range(n_runners)],
        'Poids': [f"{np.random.normal(58, 3):.1f}" for _ in range(n_runners)],
        '√Çge/Sexe': [f"{np.random.randint(3, 8)}{np.random.choice(['H', 'F'])}" for _ in range(n_runners)],
        'Jockey': [f"Jockey_{i+1}" for i in range(n_runners)],
        'Entra√Æneur': [f"Trainer_{(i % 5) + 1}" for i in range(n_runners)],
        'Cote': [f"{np.random.uniform(3, 20):.1f}" for _ in range(n_runners)]
    }
    
    return pd.DataFrame(data)

if __name__ == "__main__":
    main()
